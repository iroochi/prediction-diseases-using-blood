# -*- coding: utf-8 -*-
"""Uric acid.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CC-cgKQ4bGdFDSEEXYtiTnFxrAQPGAsM

Artificial Neural Network

Importing the dependencies
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import tensorflow as tf

"""Loading the CSV file into data frame using pandas"""

uric_df = pd.read_csv('/content/URIC ACID.csv')
uric_df

uric_df['Sex'].replace('F', 0, inplace = True)
uric_df['Sex'].replace('M', 1, inplace = True)
uric_df

"""Understanding the data"""

uric_df.shape

uric_df.head()

uric_df.tail()

uric_df.describe()

import matplotlib.pyplot as plt
import seaborn as sns
f, ax = plt.subplots(1,2,figsize = (10,5))
uric_df['Target'].value_counts().plot.pie(explode = [0,0.1], autopct = "%1.1f%%", ax = ax[0], shadow = True)
ax[0].set_title('Target')
ax[0].set_ylabel('')
sns.countplot('Target', data = uric_df, ax = ax[1])
ax[1].set_title('Target')
N, P = uric_df['Target'].value_counts()
print('Negative(0): ', N)
print('Positive(1): ', P)
plt.grid()
plt.show()

uric_df.hist(bins = 10, figsize = (10,10))
plt.show()

correlation = uric_df.corr()

correlation

sns.heatmap(correlation, annot = True)

"""Splitting the Target and other columns"""

x = uric_df.drop(columns = 'Target', axis = 1)
y = uric_df['Target']

print(x)

print(y)

"""Splitting the data into Training data and Test data"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=0)

print(x.shape, x_train.shape, x_test.shape)

print(x_train)

print(x_test)

"""Fitting and Evaluation"""

#Performing Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

print(x_train)

print(x_test)

"""Initialization ANN(Artificial Neural Network)"""

#Initialising ANN
ann_uric = tf.keras.models.Sequential()

#Adding First Hidden Layer
ann_uric.add(tf.keras.layers.Dense(units=6,activation="relu"))

#Adding Second Hidden Layer
ann_uric.add(tf.keras.layers.Dense(units=6,activation="relu"))

#Adding Output Layer
ann_uric.add(tf.keras.layers.Dense(units=1,activation="sigmoid"))

#Compiling ANN
ann_uric.compile(optimizer="adam",loss="binary_crossentropy",metrics=['accuracy'])

#Fitting ANN
ann_uric.fit(x_train,y_train,batch_size=32,epochs = 100)

y_log = ann_uric.predict(x_test)

y_pred = np.where(y_log>0.5,1,0)

from sklearn.metrics import accuracy_score
ann = accuracy_score(y_test, y_pred)
ann

ann_accuracy = accuracy_score(y_test, y_pred)*100
print("Accuracy of the Test data: " + str(round(ann_accuracy, 2))+ '%')



"""LOGISTIC REGRESSION"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
model = LogisticRegression()
# training the logistic regression model with training data
model.fit(x_train, y_train)

# accuracy score
# training data trd
x_train_pred = model.predict(x_train)
trd_accuracy = accuracy_score(x_train_pred, y_train)*100
print("Accuracy of the Training data: " + str(round(trd_accuracy, 2))+ '%')

# test data ted
x_test_pred = model.predict(x_test)
ted_accuracy = accuracy_score(x_test_pred, y_test)*100
print("Accuracy of the Test data: " + str(round(ted_accuracy, 2)) + '%')

from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, accuracy_score

sc = StandardScaler()

# training the model with training dataset
x_train = sc.fit_transform(x_train)
x_test = sc.fit_transform(x_test)

print(x_train)

print(x_test)

from sklearn.svm import SVC
svc = SVC(kernel = 'linear', random_state = 0)

svc.fit(x_train, y_train)

xtrain_svm_pred = svc.predict(x_train)

xtrain_svm_pred

confusion_matrix(y_train, xtrain_svm_pred)

accuracy_score(y_train, xtrain_svm_pred)
svm_train_accuracy = accuracy_score(y_train, xtrain_svm_pred)*100
print("Accuracy of training data is: " + str(round(svm_train_accuracy, 2)) + '%')

xtest_svm_pred = svc.predict(x_test)
xtest_svm_pred

confusion_matrix(y_test, xtest_svm_pred)

sns.heatmap(confusion_matrix(y_test,xtest_svm_pred), annot = True, fmt = "d")

accuracy_score(y_test, xtest_svm_pred)
svm_test_accuracy = accuracy_score(y_test, xtest_svm_pred)*100
print("Accuracy of the model or test data is: " + str(round(svm_test_accuracy, 2)) + '%')

"""Comparison between the three models"""

model_compare = pd.DataFrame({"Artificial Neural Network":ann_accuracy,
                              "Logistic Regression":ted_accuracy,
                              "Support Vector Machine":svm_test_accuracy,}, index = ["accuracy"])
model_compare

