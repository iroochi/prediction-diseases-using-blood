# -*- coding: utf-8 -*-
"""Glucose.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BbXk5Lp5-bwIWKV3O8XaATQ5RiZ4d3gd

Artificial Neural Network

Importing the dependencies
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import tensorflow as tf

"""Loading the CSV file into data frame using pandas library"""

glucose_data = pd.read_csv("/content/GLUCOSE(SUGAR).csv")
glucose_data

print(glucose_data.columns)

glucose_data['Sex'].replace('F', 0, inplace = True)
glucose_data['Sex'].replace('M', 1, inplace = True)
glucose_data

"""Understanding the data"""

# number of rows and columns
glucose_data.shape

# first 10 rows
glucose_data.head(10)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
h1 = glucose_data['Blood Sugar Fasting']
h2 = glucose_data['Blood Sugar Post Lunch']
legend = ['BSF', 'BSPL']
plt.hist([h1,h2], color = ['red','green'])
plt.xlabel('Level')
plt.ylabel('No. of Patients')
plt.legend(legend)
plt.title('BSF vs BSPL')
plt.show()

# statistical measures of the data
glucose_data.describe()

f, ax = plt.subplots(1,2,figsize = (10,5))
glucose_data['Target'].value_counts().plot.pie(explode = [0,0.1], autopct = "%1.1f%%", ax = ax[0], shadow = True)
ax[0].set_title('Target')
ax[0].set_ylabel('')
sns.countplot('Target', data = glucose_data, ax = ax[1])
ax[1].set_title('Target')
N, P = glucose_data['Target'].value_counts()
print('Negative(0): ', N)
print('Positive(1): ', P)
plt.grid()
plt.show()

glucose_data.hist(bins = 10, figsize = (10,10))
plt.show()

correlation = glucose_data.corr()

correlation

sns.heatmap(correlation, annot = True)

"""Splitting the Target and other columns"""

x = glucose_data.drop(columns = 'Target', axis = 1)
y = glucose_data['Target']

print(x)

print(y)

"""Splitting the data into training data and test data"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=0)

print(x.shape, x_train.shape, x_test.shape)

print(x_train)

print(x_test)

#Performing Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

print(x_train)

print(x_test)

#Initialising ANN
ann = tf.keras.models.Sequential()

#Adding First Hidden Layer
ann.add(tf.keras.layers.Dense(units=6,activation="relu"))

#Adding Second Hidden Layer
ann.add(tf.keras.layers.Dense(units=6,activation="relu"))

#Adding Output Layer
ann.add(tf.keras.layers.Dense(units=1,activation="sigmoid"))

#Compiling ANN
ann.compile(optimizer="adam",loss="binary_crossentropy",metrics=['accuracy'])

#Fitting ANN
ann.fit(x_train, y_train, batch_size=32, epochs = 100)

"""Accuracy - 91.75%"""

y_log = ann.predict(x_test)

y_pred = np.where(y_log>0.5,1,0)

from sklearn.metrics import accuracy_score
ann = accuracy_score(y_test, y_pred)
ann

ann_accuracy = accuracy_score(y_test, y_pred)*100
print("Accuracy of the Test data: " + str(round(ann_accuracy, 2))+ '%')

"""Logistic Regression"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
model = LogisticRegression()
# training the logistic regression model with training data
model.fit(x_train, y_train)

# accuracy score
# training data trd
x_train_pred = model.predict(x_train)
trd_accuracy = accuracy_score(x_train_pred, y_train)*100
print("Accuracy of the Training data: " + str(round(trd_accuracy, 2))+ '%')

# test data ted
x_test_pred = model.predict(x_test)
ted_accuracy = accuracy_score(x_test_pred, y_test)*100
print("Accuracy of the Test data: " + str(round(ted_accuracy, 2)) + '%')

"""SVM"""

from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, accuracy_score

sc = StandardScaler()

# training the model with training dataset
x_train = sc.fit_transform(x_train)
x_test = sc.fit_transform(x_test)

print(x_train)

print(x_test)

"""SVM"""

from sklearn.svm import SVC
svc = SVC(kernel = 'linear', random_state = 0)

svc.fit(x_train, y_train)

xtrain_svm_pred = svc.predict(x_train)

xtrain_svm_pred

confusion_matrix(y_train, xtrain_svm_pred)

accuracy_score(y_train, xtrain_svm_pred)
svm_train_accuracy = accuracy_score(y_train, xtrain_svm_pred)*100
print("Accuracy of training data is: " + str(round(svm_train_accuracy, 2)) + '%')

xtest_svm_pred = svc.predict(x_test)
xtest_svm_pred

confusion_matrix(y_test, xtest_svm_pred)

sns.heatmap(confusion_matrix(y_test,xtest_svm_pred), annot = True, fmt = "d")

accuracy_score(y_test, xtest_svm_pred)
svm_test_accuracy = accuracy_score(y_test, xtest_svm_pred)*100
print("Accuracy of the model or test data is: " + str(round(svm_test_accuracy, 2)) + '%')

"""Comparision between three models"""

model_compare = pd.DataFrame({"Artificial Neural Network":ann_accuracy,
                              "Logistic Regression":ted_accuracy,
                              "Support Vector Machine":svm_test_accuracy,}, index = ["accuracy"])
model_compare

